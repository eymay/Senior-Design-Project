%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% !TEX root = interimreport.tex
\clearpage
\chapter{THE LLVM COMPILER}\label{ch:Ch3}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace*{-12pt} % If no text above section, use this vspacing to lift the whole part to the proper starting point - SBÖ

LLVM is a collection of modular and flexible libraries and a toolchain software that can be used to build a wide variety of compilers and other tools. LLVM compilers consist of a set of libraries that implement the parts of a compiler. There are different front-end libraries a for every language and different back-end libraries for every architecture. There is only one common intermediate representation optimizer that connects specific front-end and back-end.

\begin{figure}
    \centering
    \includegraphics{the_llvm_compiler/llvm_diagram.png}
    \caption{Front-end and Back-end libraries connected by LLVM}
    \label{fig:llvm_diagram}
\end{figure}

LLVM IR is the common target of programming languages and is the source for every target hardware. Various LLVM front-ends translate related languages into IR. Related back-end compiles IR into assembly according to the target hardware. This structure helps to increase flexibility between front-ends and back-ends. With this structure, we are able to have compilers for every combination of $M$ source codes and $N$ targets with $M$ front-end and $N$ back-end instead of $MxN$ compilers. In our case, we do not have to deal with the front-end as our customised back-end will be lowering any input programming language thanks to LLVM IR. The front-end we use in the development process will be Clang which is the LLVM C/C++ front-end\cite{clang}.

In LLVM, instrinsic functions are internal functions and they have their semantics directly defined by LLVM itself. LLVM provides both target-independent and target-specific intrinsics. \cite{llvmdevmeeting} These intrinsics have well known semantics and names and they must adhere to certain restrictions. In general, these intrinsics serve as an expansion mechanism for the LLVM language that does not necessitate modifying all of the transformations in LLVM when introducing changes to the language. Intrinsic function names start with “llvm.” \cite{googlesiteintrinsic}

Clang supports the notion of builtin functions used in GCC. Some of these have the same syntax as in GCC to not disrupt portability. In addition to these, Clang supports other builtin functions that GCC doesn’t. Some of these are \_\_builtin\_shufflevector, \_\_builtin\_unreachable etc. As we can see, these builtin functions start with double underscores. 

Intrinsic functions and builtin functions are two seperate things and should not be confused. Builtins are at C level (source code) while intrinsics are LLVM IR level and are not exposed to the user. A builtin function may or may not be expanded into intrinsic calls. It is possible to connect a new builtin function in the front-end to an intrinsic in the middle-end.

\section{Parts of the Clang Front-end}

\subsection{Clang Lex Library}
Clang Lex Library is a typical lexer implemented as finite state machines that read source code one character at a time and transition between different states based on the characters read. The Clang lexer, which is a front-end compiler for the C, C++, and Objective-C programming languages, uses this approach to filter out comments and white space, recognize and tokenize language elements such as keywords, identifiers, and operators, and handle escape sequences and string literals. The implementation files of the Clang lexer can be found in the llvm-project/clang/lib/lex directory within the LLVM infrastructure.
	

\subsection{Clang Parse Library}

Clang Parse Library is the parser that takes the tokens produced by the lexer and constructs an abstract syntax tree (AST) to represent the structure and meaning of the source code. The Clang parser checks the source code for proper syntax and resolves symbols and identifiers. It also performs type-checking to ensure the source code follows the rules of the programming language. It creates the AST, a tree-like structure, that represents the source code in a way that is easily processed by the compiler. The implementation files of the Clang lexer can be found in the llvm-project/clang/lib/parse directory within the LLVM infrastructure.

\subsection{Clang Sema Library}

Clang Sema Library is a semantic analyzer that involves examining the meaning and context of the source code in a program. In Clang, semantic analysis is a phase in the compilation process that analyzes the abstract syntax tree (AST) generated by the parser to verify that the source code conforms to the rules of the programming language and is properly constructed. Semantic analysis performs various checks and transformations on the AST to ensure the source code is correct. The implementation files of the Clang semantic analyzer can be found in the llvm-project/clang/lib/sema directory within the LLVM infrastructure.

\subsection{Clang CodeGen Library}

Clang CodeGen is the code generation library that takes the abstract syntax tree as input which is generated by the parser and corrected by the semantic analyzer. It generates the intermediate representation code and produces a .ll file which will be used in the back-end. The implementation files of the Clang lexer can be found in the llvm-project/clang/lib/CodeGen directory within the LLVM infrastructure. 

\section{LLVM IR Optimizer}\label{sec:opt}
LLVM IR is an intermediate representation which serves as a common ground for front-ends and back-ends. LLVM IR is not as high level as programming languages but it provides more information than assembly by having types or more expressive functions. LLVM IR instructions are stored in Basic Block structures which contain sequential IR instructions with an entry and exit. 

LLVM Optimizer is a common optimization medium used for every possible source-target combination of a compiler. It takes the output file of CodeGen as input and runs three types of passes:

\begin{enumerate}
    \item Analysis passes: These passes analyze the IR and collect information about the IR without modifying the IR. 
    \item Transformation passes: These passes modify the IR by using the information gathered from Analysis passes. The optimizations are the product of these transformations. 
    \item Utility passes: These passes are used to perform tasks such as printing the IR or verifying the IR. 
\end{enumerate}

The output of the optimizer becomes the input for the target back-end which lowers the LLVM IR to the target Assembly. As the generated LLVM IR at the end of the optimizations is the object of pattern matching and assembly support for any custom instruction, it is a critical part of the design process.

\subsection{Analysis Passes}
There are almost 40 analysis passes. The significant documented analysis passes are listed below:

\begin{multicols}{3}
\begin{itemize}
\scriptsize
     \item Exhaustive Alias Analysis Precision Evaluator
     \item Basic Alias Analysis (stateless AA impl)
     \item Basic CallGraph Construction
     \item Count Alias Analysis Query Responses
     \item Dependence Analysis
     \item AA use debugger
     \item Dominance Frontier Construction
     \item Dominator Tree Construction
     \item Simple mod/ref analysis for globals
     \item Counts the various types of Instructions
     \item Interval Partition Construction
     \item Induction Variable Users
     \item Lazy Value Information Analysis
     \item LibCall Alias Analysis
     \item Statically lint-checks LLVM IR
     \item Natural Loop Information
     \item Memory Dependence Analysis
     \item Decodes module-level debug info
     \item Post-Dominance Frontier Construction
     \item Post-Dominator Tree Construction
     \item Alias Set Printer
     \item Find Used Types
     \item Detect single entry single exit regions
     \item Scalar Evolution Analysis
     \item ScalarEvolution-based Alias Analysis
     \item Stack Safety Analysis
     \item Target Data Layout

\end{itemize}
\end{multicols}


\subsection{Transformation Passes}
There are almost 60 transformation passes. The documented transformation passes are listed below:

\begin{multicols}{3}
\begin{itemize}
\scriptsize
     \item Aggressive Dead Code Elimination
     \item Inliner for always\_inline functions
     \item Promote ‘by reference’ arguments to scalars
     \item Basic-Block Vectorization
     \item Profile Guided Basic Block Placement
     \item Break critical edges in CFG
     \item Optimize for code generation
     \item Merge Duplicate Global Constants
     \item Dead Code Elimination
     \item Dead Argument Elimination
     \item Dead Type Elimination
     \item Dead Instruction Elimination
     \item Dead Store Elimination
     \item Deduce function attributes
     \item Dead Global Elimination
     \item Global Variable Optimizer
     \item Global Value Numbering
     \item Canonicalize Induction Variables
     \item Function Integration/Inlining
     \item Combine redundant instructions
     \item Combine expression patterns
     \item Internalize Global Symbols
     \item Interprocedural Sparse Conditional Constant Propagation
     \item Jump Threading
     \item Loop-Closed SSA Form Pass
     \item Loop Invariant Code Motion
     \item Delete dead loops
     \item Extract loops into new functions
     \item Extract at most one loop into a new function
     \item Loop Strength Reduction
     \item Rotate Loops
     \item Canonicalize natural loops
     \item Unroll loops
     \item Unroll and Jam loops
     \item Unswitch loops
     \item Lower global destructors
     \item Lower atomic intrinsics to non-atomic form
     \item Lower invokes to calls, for unwindless code generators
     \item Lower SwitchInsts to branches
     \item Promote Memory to Register
     \item MemCpy Optimization
     \item Merge Functions
     \item Unify function exit nodes
     \item Partial Inliner
     \item Remove unused exception handling info
     \item Reassociate expressions
     \item Relative lookup table converter
     \item Demote all values to stack slots
     \item Scalar Replacement of Aggregates
     \item Sparse Conditional Constant Propagation
     \item Simplify the CFG
     \item Code sinking
     \item Strip all symbols from a module
     \item Strip debug info for unused symbols
     \item Strip Unused Function Prototypes
     \item Strip all llvm.dbg.declare intrinsics
     \item Strip all symbols, except dbg symbols, from a module
     \item Tail Call Elimination

\end{itemize}
\end{multicols}

\cite{passes}

\subsection{Case Study: Optimizations on S-box }\label{sbox-case}
%TODO Add ASCON introduction to explain what S-box is
One of the research topics of this study was to observe the changes to a function shown in Code \ref{lst:sbox-c} performing S-box with bitwise operations. As the pattern is large hundreds of lines of LLVM IR and RISC-V Assembly are generated without enabling optimizations. The unoptimized LLVM IR is given in Appendices in Code shown in Code \ref{lst:unopt-sbox}. However, when the optimizations are enabled the final LLVM IR file shown in Code \ref{lst:sbox-ir} and the RISC-V Assembly is significantly smaller. 

\begin{minipage}{\linewidth}
\lstinputlisting[caption={S-box C code},language=C, label={lst:sbox-c}]{../s-box/s-box.c}
\end{minipage}

At the end of optimization passes the following IR will be generated:
\begin{minipage}{\linewidth}
\lstinputlisting[caption={Optimized S-box LLVM IR}, label={lst:sbox-ir},language=llvm,style=nasm]{../s-box/opt/postOrderFuncAttrs.ll}
\end{minipage}
LLVM optimization passes are responsible for the simplification of IR. In this case, the following passes were the passes changing the IR and were run sequentially.
\begin{enumerate}
    \item InferFunctionAttrsPass 
    \item SROAPass 
    \item EarlyCSEPass 
    \item GlobalOptPass 
    \item InstCombinePass 
    \item EarlyCSEPass 
    \item InstCombinePass 
    \item ReassociatePass 
    \item InstCombinePass 
    \item DSEPass 
    \item PostOrderFunctionAttrsPass 
\end{enumerate}
 As it can be observed some passes can run several times. For example InstCombinePass runs to canonicalize and prepare the expressions for the following pass which is the reason why it is running prior to three distinct passes.


 \subsubsection{Infer Function Attributes - InferFunctionAttrsPass}\label{sec:funcAttrs}

 This pass adds metadata to LLVM IR, by analyzing it. Function attributes are used to pass information about functions between LLVM passes.

 \lstinputlisting[caption={LLVM IR Before InferFunctionAttrsPass},linerange={181-185} , label={lst:sbox-preinfFuncAttr},language=llvm, style=nasm]{../s-box/opt/unoptimized.ll}
 \lstinputlisting[caption={LLVM IR After InferFunctionAttrsPass},linerange={181-185} , label={lst:sbox-infFuncAttr},language=llvm, style=nasm]{../s-box/opt/inferFunctionAttrs.ll}

 Function attribute is inferred as "mustprogress" as the lifetime starting function is interacting with its environment in an observable way making a memory access \cite{llvmref-funcAttrs}. 
 \par
The lifetime function decides the accessibility of the pointer to the memory. When memory is allocated the lifetime of pointer to the memory starts and ends when deallocated \cite{llvmref-objectLifetime}.

\subsubsection{Scalar Replacement of Aggregates - SROAPass}

Aggregate IR instructions such as "alloca" are promoted to registers. The promotion to registers also means the lifetime is under control and the explicit lifetime intrinsic calls can be removed.

 \lstinputlisting[caption={Alloca and Lifetime Start Lines Removed From LLVM IR Before SROAPass},linerange={11-22} ,language=llvm, style=nasm]{../s-box/opt/inferFunctionAttrs.ll}
 \lstinputlisting[caption={Lifetime End Lines Removed From LLVM IR Before SROAPass},linerange={172-177} ,language=llvm, style=nasm]{../s-box/opt/inferFunctionAttrs.ll}

An important transformation SROA does is promoting the use of registers instead of using the stack for local variables and using "Load/Store" operations to use them in the unoptimized IR \cite{llvmcode-sroa}. "Store/Load" operations are reduced significantly in this stage, especially for intermediate variables where the C code is not referring to the array directly. 

SROA pass relies on the analysis passes of Alias Analysis through the collection of analysis passes for Loads.

\lstinputlisting[linerange={15-19}, caption={NOT operations between Intermediate Variables} ,language=C, label={lst:sbox-c-nots}]{../s-box/s-box.c}

 \lstinputlisting[caption={Intermediate Load and Stores in LLVM IR Before SROAPass},linerange={66-81} , language=llvm, style=nasm]{../s-box/opt/inferFunctionAttrs.ll}

 \lstinputlisting[caption={Load and Stores Promoted to Registers in LLVM IR After SROAPass},linerange={45-49} ,label={sbox-sroa} , language=llvm, style=nasm]{../s-box/opt/SROAPass.ll}

Similar to the dramatic change in the previous example, operations between the array elements and the intermediate variables are optimized so that the registers are used instead of the stack.

According to the statistics obtained from the "opt" tool of LLVM:

\begin{displayquote}
 5 mem2reg - Number of alloca's promoted within one block \\
 1 mem2reg - Number of alloca's promoted with a single store \\
 1 sroa    - Maximum number of partitions per alloca \\
 8 sroa    - Maximum number of uses of a partition \\
41 sroa    - Number of alloca partition uses rewritten \\
 6 sroa    - Number of alloca partitions formed \\
 6 sroa    - Number of allocas analyzed for replacement \\
41 sroa    - Number of instructions deleted \\
 6 sroa    - Number of allocas promoted to SSA values \\
\end{displayquote}

\subsubsection{Early Common Subexpression Elimination - EarlyCSEPass}\label{sec:earlyCSE1}
Performs a simple dominator tree walk, eliminating trivially redundant instructions. Dominator tree is a type of tree where every parent node dominates the child node. The definition of dominance from graph theory is that every path to the dominated node passes through the dominator node \cite{prosserDom}.

Early CSE pass relies on MemorySSA analysis which analyses by representing memory operations in SSA form \cite{llvmdoc-memoryssa, novillo2007memory}.

 \lstinputlisting[caption={Redundant Load Instructions in LLVM IR Before EarlyCSEPass},linerange={4-11},label={lst:sbox-cse1}, language=llvm, style=nasm]{../s-box/opt/SROAPass.ll}
In Code \ref{lst:sbox-cse1} you can see that "\%x1" and "\%arrayidx2" are equal to the function argument "\%state". EarlyCSE pass detects this redundant condition and uses the already present "\%state" pointer in the output.

\lstinputlisting[caption={Optimized Load Instructions in LLVM IR After EarlyCSEPass},linerange={2-6} , label={lst:sbox-cseLoad}, language=llvm, style=nasm]{../s-box/opt/earlyCSE.ll}

Another remark from this example is that the pointer calculation is done in two instructions by "getelementptr" LLVM instruction which accesses the struct's address and then the element's address in it. EarlyCSE combines these two instructions outputting the offset calculated pointers.

A natural result of these simple optimizations is that the section which makes use of registers has increased. It can be seen in Code \ref{lst:sbox-cse2} that the recalculation of pointers by getelementptr is removed as they are used at the beginning of the function, as shown partly in Code \ref{lst:sbox-cseLoad}.

\begin{minipage}{\linewidth}
\lstinputlisting[caption={Redundant Instructions in LLVM IR Before EarlyCSEPass},linerange={30-69},label={lst:sbox-cse2}, language=llvm, style=nasm-small]{../s-box/opt/SROAPass.ll}
\end{minipage}

 \lstinputlisting[caption={Optimized LLVM IR After EarlyCSEPass},linerange={20-33} ,label={lst:sbox-cse3}, language=llvm, style=nasm]{../s-box/opt/earlyCSE.ll}

Register-based operations increased because redundant load operations from the same pointers are removed. For example, in Code \ref{lst:sbox-cse2} to obtain "\%and", register operation result "\%not" and loaded value "\%11" are used. In the output of EarlyCSE, Code \ref{lst:sbox-cse3}, we can see that instead of reloading to register the loaded register is used, "\%7" in this case.

According to the statistics obtained from the "opt" tool of LLVM:
\begin{displayquote}
19 early-cse - Number of instructions Common Subexpression Eliminated \\
 7 early-cse - Number of load instructions Common Subexpression Eliminated \\
35 early-cse - Number of instructions simplified or Dead Code Eliminated \\
\end{displayquote}


\subsubsection{Optimize Global Variables - GlobalOpt}
This pass aims to optimize global variables and transforms them to constants if necessary. This pass did not significantly change the IR. It only added an attribute to the function, "local\_unnamed\_addr" meaning that the address of the function is not significant in the module.

\lstinputlisting[caption={"local\_unnamed\_addr" Attribute Added to LLVM IR After GlobalOpt},linerange={7-7} ,label={lst:sbox-globvar}, language=llvm, style=nasm]{../s-box/opt/globalOptPass.ll}

\subsubsection{Combine Redundant Instructions - InstCombinePass}
%TODO move transform explanations to Transforms section and only explain the example code here
Combines redundant instructions and canonicalizes them. Canonicalization is the form in which a single way of commutability is preferred. For example, if a binary operator has a constant operand it is moved to the right. Canonic instructions can then be used by other passes which can assume the instructions to be in the canonic form \cite{llvmpass-instcombine}.
\par 

\lstinputlisting[caption={Redundant Load Instruction in LLVM IR Before InstCombine},linerange={10-17} ,label={lst:sbox-instc1_1}, language=llvm, style=nasm]{../s-box/opt/globalOptPass.ll}

\begin{minipage}{\linewidth}
\lstinputlisting[caption={Removed Load Instruction in LLVM IR After InstCombine},linerange={4-11} , language=llvm, style=nasm]{../s-box/opt/instCombine1.ll}
\end{minipage}

According to the statistics obtained from the "opt" tool of LLVM:
\begin{displayquote}
  5 aa             - Number of NoAlias results \\
109 assume-queries - Number of Queries into an assume assume bundles \\
 10 basicaa        - Number of times a GEP is decomposed \\
 11 instcombine    - Number of insts combined \\
  1 instcombine    - Number of expansions \\
  2 instcombine    - Number of instruction combining iterations performed \\
\end{displayquote}

\subsubsection{Early Common Subexpression Elimination - 2nd Run of EarlyCSEPass}
Similar to the previous EarlyCSE run in Section \ref{sec:earlyCSE1}, load instructions to registers are reused in the subsequent instructions.
\lstinputlisting[caption={Redundant Load Instructions in LLVM IR Before 2nd EarlyCSEPass},linerange={34-48} ,label={lst:sbox-cse2_1}, language=llvm, style=nasm]{../s-box/opt/instCombine1.ll}

\begin{minipage}{\linewidth}
\lstinputlisting[caption={Removed Load Instructions in LLVM IR After 2nd EarlyCSEPass},linerange={31-39} ,label={lst:sbox-cse2_2}, language=llvm, style=nasm]{../s-box/opt/earlyCSE2.ll}
\end{minipage}

%TODO $LLVMFULLBIN/opt -S instCombine1.ll -passes=early-cse -stats
%Gives no change in the output, so no stats
%https://llvm.org/devmtg/2020-09/slides/Schmeiser-Understanding_Changes_made_by_pass_in_the_opt_pipeline.pdf

\subsubsection{Combine Redundant Instructions - 2nd Run of InstCombinePass}

\lstinputlisting[caption={XOR Instruction in LLVM IR Before InstCombine},linerange={4-5,9-11,22-22,27-27} ,label={lst:sbox-instc2-1}, language=llvm, style=nasm]{../s-box/opt/earlyCSE2.ll}

\lstinputlisting[caption={XOR Instruction in LLVM IR After InstCombine},linerange={4-5,9-10,22-22,27-27} ,label={lst:sbox-instc2_2}, language=llvm, style=nasm]{../s-box/opt/instCombine2.ll}

The first algebraic optimization in the process can be observed in this example. In Code \ref{lst:sbox-instc2-1}, to obtain "\%and37" the boolean operations of the following must be performed:

$$ (\%0 \oplus \%2)  \land ( \%2 \oplus -1)  $$
It can be shown that a simpler boolean form can be obtained by transitioning equivalent boolean equations:
$$ (\%0 \oplus \%2)  \land  \lnot \%2   $$
$$ ((\%0 \land \lnot \%2) \lor (\lnot \%0 \land \%2))  \land  \lnot \%2   $$
$$ (\%0 \land \lnot \%2\land  \lnot \%2) \lor (\lnot \%0 \land \%2\land  \lnot \%2)     $$
$$ (\%0 \land \lnot \%2) \lor (0)     $$
$$ \%0 \land (\%2 \oplus -1) $$

In Code \ref{lst:sbox-instc2_2}, the redundant operation $\%0 \oplus \%2$ is removed and the result is: 

$$ \%0  \land ( \%2 \oplus -1)  $$

According to the statistics obtained from the "opt" tool of LLVM:
\begin{displayquote}
60 assume-queries - Number of Queries into an assume assume bundles \\
 5 instcombine    - Number of insts combined \\
 1 instcombine    - Number of expansions \\
 2 instcombine    - Number of instruction combining iterations performed \\ 
12 instsimplify   - Number of reassociations \\
\end{displayquote}

\subsubsection{Reassociate Expressions - ReassociatePass}
Reassociates associative expressions, to promote better constant propagation and simplify expression graph to reduce instruction count. It implements an algorithm where the constants have the least rank and the rank increases with the expression reverse post-order traversal \cite{llvmcode-reassoc}. 

\lstinputlisting[caption={Instructions in LLVM IR Before ReassociatePass},linerange={26-29} ,label={lst:sbox-reass}, language=llvm, style=nasm]{../s-box/opt/instCombine2.ll}

\lstinputlisting[caption={Instructions with Reassociated Arguments in LLVM IR After ReassociatePass},linerange={26-29} ,label={lst:sbox-reass2}, language=llvm, style=nasm]{../s-box/opt/reassociatePass.ll}

A basic glance at the debug output of the pass gives more idea about how the reassociation works.
\clearpage
\begin{lstlisting}[language=llvm, style=nasm, caption={Debug Output of Reassociate Pass from LLVM opt tool}]
Calculated Rank[state] = 3
Combine negations for:   %xor = xor i32 %0, %1
LINEARIZE:   %xor = xor i32 %0, %1
OPERAND:   %0 = load i32, ptr %arrayidx, align 4, !tbaa !7 (1)
ADD USES LEAF:   %0 = load i32, ptr %arrayidx, align 4, !tbaa !7 (1)
OPERAND:   %1 = load i32, ptr %state, align 4, !tbaa !7 (1)
ADD LEAF:   %1 = load i32, ptr %state, align 4, !tbaa !7 (1)
RAIn:	xor i32	[ %0, #262145] [ %1, #262146]
RAOut:	xor i32	[ %1, #262146] [ %0, #262145]
RA:   %xor = xor i32 %0, %1
TO:   %xor = xor i32 %1, %0
Combine negations for:   %xor7 = xor i32 %0, %2
LINEARIZE:   %xor7 = xor i32 %0, %2
OPERAND:   %0 = load i32, ptr %arrayidx, align 4, !tbaa !7 (1)
ADD USES LEAF:   %0 = load i32, ptr %arrayidx, align 4, !tbaa !7 (1)
OPERAND:   %2 = load i32, ptr %arrayidx4, align 4, !tbaa !7 (1)
ADD USES LEAF:   %2 = load i32, ptr %arrayidx4, align 4, !tbaa !7 (1)
RAIn:	xor i32	[ %0, #262145] [ %2, #262148]
RAOut:	xor i32	[ %2, #262148] [ %0, #262145]
RA:   %xor7 = xor i32 %0, %2
TO:   %xor7 = xor i32 %2, %0
\end{lstlisting}

The debug output deals with the beginning of the function which is given below.


\lstinputlisting[caption={Instructions in LLVM IR Before ReassociatePass},linerange={5-11} ,label={lst:sbox-reass}, language=llvm, style=nasm]{../s-box/opt/instCombine2.ll}
The pass computed that the reassociation would result in the instruction "\%xor = xor i32 \%1, \%0" which is already how the IR is so it is not changed. However, as it can be seen in Code \ref{lst:sbox-reass2}, "\%xor7 = xor i32 \%2, \%0" replaced its alternative representation as the rank of "\%0" is less than "\%2". 


According to the statistics obtained from the "opt" tool of LLVM:
\begin{displayquote}
    16 reassociate - Number of insts reassociated
\end{displayquote}


\subsubsection{Combine Redundant Instructions - 2nd Run of InstCombinePass}
In this last run of InstCombinePass instruction count is not changed. Some reassociations by the previous pass are reversed.

\lstinputlisting[caption={Instructions in LLVM IR Before the 3rd InstCombinePass},linerange={26-29} ,label={lst:sbox-instc3_1}, language=llvm, style=nasm]{../s-box/opt/reassociatePass.ll}

\lstinputlisting[caption={Instructions with Reassociated Arguments in LLVM IR After InstCombinePass},linerange={26-29} ,label={lst:sbox-instc3_2}, language=llvm, style=nasm]{../s-box/opt/instCombine3.ll}

Though it may seem wasteful, it is a common theme in LLVM that some transformations may be done and be completely reversed by another pass. 


According to the statistics obtained from the "opt" tool of LLVM:
\begin{displayquote}
60 assume-queries - Number of Queries into an assume assume bundles \\
 7 instcombine    - Number of insts combined \\
 2 instcombine    - Number of instruction combining iterations performed \\
12 instsimplify   - Number of reassociations \\
\end{displayquote}


\subsubsection{Dead Store Elimination - DSEPass}
Dead code in the Dead Code Elimination pass refers to the variables in any point of the program which are not used in the future. DCE does not eliminate control flow and store instructions, for this reason Dead Store Elimination pass is used to simplify the store instructions of the given program.

Trivial dead stores are eliminated. As the load operations are optimized, most of the store instructions become dead meaning that they do not affect the flow in any way.

Similar to Early CSE pass in Section \ref{sec:earlyCSE1}, DSE pass relies on Memory SSA analysis.

\lstinputlisting[caption={Redundant Store Instructions in LLVM IR Before DSEPass},linerange={30-36} ,label={lst:sbox-dse1}, language=llvm, style=nasm]{../s-box/opt/instCombine3.ll}

\lstinputlisting[caption={Removed Store Instructions in LLVM IR After DSEPass},linerange={27-29} ,label={lst:sbox-dse2}, language=llvm, style=nasm]{../s-box/opt/DSE.ll}

To see how the DSE works we can observe two dead Store's and a killer Store, unnecessary code is stripped away.

\lstinputlisting[caption={Store Instructions to the Same Address in LLVM IR Before DSEPass},linerange={2-2, 8-8, 30-30, 42-42} ,label={lst:sbox-dse3}, language=llvm, style=nasm]{../s-box/opt/instCombine3.ll}

Here is the debug output of the DSE pass.

\begin{lstlisting}[language=llvm, style=nasm, caption={Debug Output of DSE Pass from LLVM opt tool}]
Trying to eliminate MemoryDefs killed by 4 = MemoryDef(3) (
store i32 %xor43, ptr %state)
  trying to get dominating access
   visiting 3 = MemoryDef(2)->liveOnEntry (store i32 %xor12, ptr %arrayidx11)
   visiting 2 = MemoryDef(1)->liveOnEntry (store i32 %xor7, ptr %arrayidx)
   visiting 1 = MemoryDef(liveOnEntry) (store i32 %xor, ptr %state)
  Checking for reads of 1 = MemoryDef(liveOnEntry) (store i32 %xor, ptr %state)
   4 = MemoryDef(3)->1 (  store i32 %xor43, ptr %state)
    ... skipping killing def/dom access
   2 = MemoryDef(1)->liveOnEntry (store i32 %xor7, ptr %arrayidx)
   3 = MemoryDef(2)->liveOnEntry (store i32 %xor12, ptr %arrayidx11)
 Checking if we can kill 1 = MemoryDef(liveOnEntry) (store i32 %xor, ptr %state)
DSE: Remove Dead Store:
  DEAD:   store i32 %xor, ptr %state
  KILLER:   store i32 %xor43, ptr %state
  trying to get dominating access
   visiting 0 = MemoryDef(liveOnEntry)
   ...  found LiveOnEntryDef
  finished walk
  .
  .
  .
  Trying to eliminate MemoryDefs killed by 10 = MemoryDef(9) (
  store i32 %xor65, ptr %state)
  trying to get dominating access
   visiting 9 = MemoryDef(8) (store i32 %xor60, ptr %arrayidx9)
   visiting 8 = MemoryDef(7) (store i32 %xor55, ptr %arrayidx)
   visiting 7 = MemoryDef(6)->liveOnEntry (store i32 %xor52, ptr %arrayidx4)
   visiting 6 = MemoryDef(4) (store i32 %xor49, ptr %arrayidx11)
   visiting 4 = MemoryDef(liveOnEntry) (store i32 %xor43, ptr %state)
  Checking for reads of 4 = MemoryDef(liveOnEntry) (store i32 %xor43, ptr %state)
   10 = MemoryDef(9)->4 (store i32 %xor65, ptr %state)
    ... skipping killing def/dom access
   6 = MemoryDef(4) (store i32 %xor49, ptr %arrayidx11)
   9 = MemoryDef(8) (store i32 %xor60, ptr %arrayidx9)
   7 = MemoryDef(6)->liveOnEntry (store i32 %xor52, ptr %arrayidx4)
   8 = MemoryDef(7) (store i32 %xor55, ptr %arrayidx)
 Checking if we can kill 4 = MemoryDef(liveOnEntry) (
 store i32 %xor43, ptr %state)
DSE: Remove Dead Store:
  DEAD:   store i32 %xor43, ptr %state
  KILLER:   store i32 %xor65, ptr %state
  trying to get dominating access
   visiting 0 = MemoryDef(liveOnEntry)
   ...  found LiveOnEntryDef
  finished walk
\end{lstlisting}

It can be observed that whenever the DSE encounters a Store instruction with the same address as a previous Store instruction, kills the previous instruction. The last Store instruction survives DSE.

According to the statistics obtained from the "opt" tool of LLVM:
\begin{displayquote}
14 aa              - Number of MustAlias results \\
62 aa              - Number of NoAlias results \\
30 basicaa         - Number of times a GEP is decomposed \\
29 dse             - Number iterations check for reads in getDomMemoryDef \\
 0 dse             - Number of other instrs removed \\
 7 dse             - Number of stores deleted \\
 7 dse             - Number of times a valid candidate is returned from getDomMemoryDef \\
 5 dse             - Number of stores remaining after DSE \\
 1 ir              - Number of renumberings across all blocks \\
71 memory-builtins - Number of arguments with unsolved size and offset \\
\end{displayquote}

\subsubsection{Post-Order Function Attributes Pass - PostOrderFunctionAttrsPass}
This pass is similar to the InferFunctionAttrsPass in Section \ref{sec:funcAttrs}. It does not change the IR, adds metadata to it for the other passes.

\begin{minipage}{\linewidth}
\lstinputlisting[caption={Function Attributes After PostOrderFunctionAttrsPass},linerange={1-2} ,label={lst:sbox-post2}, language=llvm, style=nasm]{../s-box/opt/DSE.ll}
\end{minipage}

\lstinputlisting[caption={Function Attributes Before PostOrderFunctionAttrsPass},linerange={1-2} ,label={lst:sbox-post1}, language=llvm, style=nasm]{../s-box/opt/postOrderFuncAttrs.ll}

The added attributes signal that the function does not deallocate memory, does not recurse by calling itself, never raises an exception, will continue execution at the end according to the call stack, and may read or write any memory. 

In the end of optimization passes, the IR at Code \ref{lst:sbox-ir} will be generated.

\subsection{Clang Optimization Levels}
It should be noted that in order to observe an optimised Assembly, the LLVM IR should be generated by enabling optimizations.
Clang can be invoked with optimization levels deciding which optimization passes are going to be run. The optimizations can target speed or code size. Speed optimizing options range from "-O1" to "-O3". "-O2" enables most of the optimizations. "-O3" enables optimizations that can increase the compile time and generate larger code. The main code optimizing options are "-Os" and "-Oz". "-Os" is similar to "-O2" but runs extra optimizations to reduce code size. "-Oz" runs more code-reducing optimizations compared to "-Os" and is similar to "-O2" again \cite{clangCommands}.
Caution must be taken as when no arguments are given to Clang, at the time of writing, Clang uses the "-O0" optimization level. Implementing pattern matching on unoptimized LLVM IR is not feasible for several reasons. Firstly, the IR is more sensitive to changes in the front-end. Changing the code style in front-end can cause CodeGen to produce a slightly different IR which makes it less predictable. Secondly, the code size can be too large with redundant code which makes pattern matching large instructions cumbersome. We recommend using "-O2" or "-Os" optimization levels while developing instruction selection patterns. 

LLVM optimizations can be performed with an LLVM IR input by using the "opt" tool \cite{optimizer}. It is possible to experiment with different optimizations and observe their results on the output.

\section{Stages of the LLVM RISC-V Back-end}
LLVM RISC-V back-end is responsible for compiling optimized IR down to RISC-V assembly or object code. LLVM back-end consists of libraries for the code generation steps\cite{llvmbackend}.

\subsection{Instruction Selection}
SelectionDAG is the default instruction selector of LLVM RISC-V back-end which is responsible for selecting the appropriate RISC-V instructions for a given intermediate representation instruction. It takes the target-independent LLVM code as input and generates the target-dependent DAG of instructions. SelectionDAG is at the core of this study since we will be dealing with adding new instructions to the RISC-V back-end. 


\subsubsection{SelectionDAG construction}
After IR generation is done, SelectionDAG gets the optimized IR and converts it into target-independent SelectionDAG representation. SelectionDAG consists of SelectionDAG nodes which are created by SelectionDAGBuilder class. SelectionDAGIsel visits all the IR instructions and uses the SelectionDAGBuilder class. The relevant instruction method requests an SDNode to the DAG and assigns its opcode. Every SDNode(SelectionDAG node) has an opcode for the operation it represents. SDNodes have multiple values to return as the result. SDValues(SelectionDAG value) hold the information to determine which number to return. SelectionDAGBuilder class reshapes the linear IR input to a SelectionDAG tree form. At the and of the construction SelectionDAG is a target-independent and illegal DAG.

\subsubsection{SelectionDAG legalization}
SelectionDAG is a target-dependent representation after the construction stage of the instruction selection. Before creating a target-specific code, SelectionDAG checks if the DAG is legal because the constructed DAG may include incompatible instructions and data types to the target architecture \cite{legalizer}. SelectionDAG legalization refers to the process of transforming the SelectionDAG according to the constraints and requirements of the target architecture. Legalization may involve adding, removing, splitting or merging the nodes which targets to match the register file and instruction set of the target architecture \cite{llvmcookbook}. SelectionDAG legalization also ensures that the data type of the target architecture is compatible with the target architecture by truncating or promoting the data types. For example, if SelectionDAG includes i32 data type nodes targeted to an i64 architecture, SDlegalizer promotes the i32 nodes into i64 data type. For every target architecture type, IselLowering.cpp files are responsible for legalizing the SelectionDAG. SDlegalizer legalizes the illegal DAG into a supported form and ensures that the generated code is efficient and compatible with the target architecture.\\
An example of legalizing the SelectionDAG by truncating the i64 data type DAG into i32 data type target architecture is shown in Code \ref{lst:ir_legalization}. IR code includes i64 data type variables however, target architecture supports only i32 data type. Before the legalization(Figure \ref{fig:dag_before_legalization}) DAG is not converted to the target data type yet and it needed to become i64 compatible. It can be seen that after legalization(Figure \ref{fig:dag_after_legalization}), i32 nodes are truncated and there are no i64 nodes in the DAG.

\begin{lstlisting}[caption={Intermediate Representation code input for legalization example}, label={lst:ir_legalization}, language=llvm, style=nasm]
  define i64 @test(i64 %a, i64 %b, i64 %c) {
    %mul = mul nsw i64 %a, %b
    %add = add i64 %mul, %c
    ret i64 %add
    }
  \end{lstlisting}

\begin{figure}
  \centering
  \includegraphics[scale=0.5]{the_llvm_compiler/dag_before_legalization.png}
  \caption{DAG diagram before the legalization stage}
  \label{fig:dag_before_legalization}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.35]{the_llvm_compiler/dag_after_legalization.png}
  \caption{DAG diagram after the legalization stage}
  \label{fig:dag_after_legalization}
\end{figure}

\clearpage
\subsubsection{SelectionDAG optimization}
The DAG should be optimized after legalization because legalization phase may create unnecessary DAG nodes and the reducable nodes are not combined yet. SelectionDAG optimizer minimizes the DAG nodes before creating the target-specific instructions.

\subsubsection{SelectionDAG target-dependent instruction selection}
At the last phase of the instruction selection, SelectionDAG selects the suitable instructions for the target architecture. SelectionDAG uses the relevant TableGen target description (.td) files or C++ logic to match the patterns and replaces the patterns with the target-specific instructions.

\subsection{Scheduling and Formation}
Scheduling is the phase of assigning an order to the DAG form of RISC-V instructions. The formation phase is responsible for converting the DAG into a list of machine instructions.  

\subsection{SSA-based Machine Code Optimizations}
LLVM uses static single assignment (SSA) based optimizations before register allocation. SSA optimizations ensure that each variable is assigned and defined only once before it is used. 


\subsection{Register Allocation}
The register allocation is responsible for assigning physical registers to virtual registers in the IR. Each target has a specific register count and order. Register allocator maps the registers by taking the RISC-V architecture registers into account. It uses the relevant TargetRegisterInfo, and MachineOperand classes. 

\subsection{Prolog/Epilog Code Insertion}
Prolog and epilog code insertion is another optimization phase that is responsible for frame-pointer elimination and stack packing.

%TODO https://llvm.org/docs/CodeGenerator.html#the-mc-layer
%MCInst Açıklama
\subsection{Code Emission}
The code emission stage is responsible for lowering the code generator abstractions down to the MC layer abstractions. It takes the assembly as input and creates the final RISC-V machine codes. 

\subsection{Linking}
LLD is the LLVM linker library that is responsible for combining multiple object files into a single executable file. LLD is invoked after the code emission and generates a file by resolving symbol references, adjusting addresses, and performing other tasks as necessary.
